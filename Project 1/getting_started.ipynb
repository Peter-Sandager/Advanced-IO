{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cars: Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import pyblp\n",
    "sns.set_theme()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pyblp.options.digits = 2\n",
    "pyblp.options.verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data\n",
    "\n",
    "The dataset, `cars.csv`, contains cleaned and processed data. If you want to make changes, the notebook, `materialize.ipynb`, creates the data from the raw source datsets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv('cars.csv') # this reads the *balanced* dataset (i.e. J = 40 products per market always)\n",
    "# cars = pd.read_excel('cars.xlsx') # this reads the *unbalanced* dataset (i.e. J varies over time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No data for France pre 1990. Average growth in adult fraction from other countries applied each year before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PSand\\AppData\\Local\\Temp\\ipykernel_27920\\553329577.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cars['adults'][idx] = AdultFrac[cars['ma'][idx]][cars['ye'][idx]]\n"
     ]
    }
   ],
   "source": [
    "AdultFrac = pd.read_excel(\"FracOver20.xlsx\", index_col = 0)\n",
    "cars['adults'] = None\n",
    "for idx in cars.index:\n",
    "    cars['adults'][idx] = AdultFrac[cars['ma'][idx]][cars['ye'][idx]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We estimate that 77% of the adult population have a driving license for a full-car. Hence, the share of population aged 20+ with a driver becomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "license_share = 0.77\n",
    "cars[\"ad_w_li\"] = cars[\"adults\"] * license_share "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl_vars = pd.read_csv('labels_variables.csv', index_col=0)\n",
    "lbl_vals = pd.read_stata('cars.dta', iterator=True).value_labels() # the values that variables take (not relevant for all )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "tab = cars.mean(numeric_only=True).apply(lambda x: f'{x:.2f}').to_frame('Mean').join(lbl_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price variables \n",
    "\n",
    "Can be either price (`pr`), price-to-income (`princ`), or log price (`logp`, created below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_var = 'eurpr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars['logp'] = np.log(cars[price_var])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Market share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total quantity of cars sold in market-year (ma, ye)\n",
    "cars['qu_tot'] = cars.groupby(['ma', 'ye'])['qu'].transform('sum')\n",
    "cars['market_size'] = cars['pop'] * cars['ad_w_li']\n",
    "cars['s'] = cars['qu'] / cars['market_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outside share is from 93.1% to 97.1%\n"
     ]
    }
   ],
   "source": [
    "# compute the share of the outside good (will be useful for the demand inversion)\n",
    "cars['s0'] = 1.0 - cars.groupby(['ma', 'ye'])['s'].transform('sum')\n",
    "print(f'Outside share is from {cars.s0.min():.1%} to {cars.s0.max():.1%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_5c450\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5c450_level0_col0\" class=\"col_heading level0 col0\" >count</th>\n",
       "      <th id=\"T_5c450_level0_col1\" class=\"col_heading level0 col1\" >unique</th>\n",
       "      <th id=\"T_5c450_level0_col2\" class=\"col_heading level0 col2\" >top</th>\n",
       "      <th id=\"T_5c450_level0_col3\" class=\"col_heading level0 col3\" >freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >ma</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5c450_level0_row0\" class=\"row_heading level0 row0\" >Belgium</th>\n",
       "      <td id=\"T_5c450_row0_col0\" class=\"data row0 col0\" >1200.000</td>\n",
       "      <td id=\"T_5c450_row0_col1\" class=\"data row0 col1\" >1194.000</td>\n",
       "      <td id=\"T_5c450_row0_col2\" class=\"data row0 col2\" >0.003</td>\n",
       "      <td id=\"T_5c450_row0_col3\" class=\"data row0 col3\" >2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5c450_level0_row1\" class=\"row_heading level0 row1\" >France</th>\n",
       "      <td id=\"T_5c450_row1_col0\" class=\"data row1 col0\" >1200.000</td>\n",
       "      <td id=\"T_5c450_row1_col1\" class=\"data row1 col1\" >1199.000</td>\n",
       "      <td id=\"T_5c450_row1_col2\" class=\"data row1 col2\" >0.001</td>\n",
       "      <td id=\"T_5c450_row1_col3\" class=\"data row1 col3\" >2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5c450_level0_row2\" class=\"row_heading level0 row2\" >Germany</th>\n",
       "      <td id=\"T_5c450_row2_col0\" class=\"data row2 col0\" >1200.000</td>\n",
       "      <td id=\"T_5c450_row2_col1\" class=\"data row2 col1\" >1199.000</td>\n",
       "      <td id=\"T_5c450_row2_col2\" class=\"data row2 col2\" >0.000</td>\n",
       "      <td id=\"T_5c450_row2_col3\" class=\"data row2 col3\" >2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5c450_level0_row3\" class=\"row_heading level0 row3\" >Italy</th>\n",
       "      <td id=\"T_5c450_row3_col0\" class=\"data row3 col0\" >1200.000</td>\n",
       "      <td id=\"T_5c450_row3_col1\" class=\"data row3 col1\" >1195.000</td>\n",
       "      <td id=\"T_5c450_row3_col2\" class=\"data row3 col2\" >0.000</td>\n",
       "      <td id=\"T_5c450_row3_col3\" class=\"data row3 col3\" >2.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5c450_level0_row4\" class=\"row_heading level0 row4\" >UK</th>\n",
       "      <td id=\"T_5c450_row4_col0\" class=\"data row4 col0\" >1200.000</td>\n",
       "      <td id=\"T_5c450_row4_col1\" class=\"data row4 col1\" >1199.000</td>\n",
       "      <td id=\"T_5c450_row4_col2\" class=\"data row4 col2\" >0.000</td>\n",
       "      <td id=\"T_5c450_row4_col3\" class=\"data row4 col3\" >2.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x26c7d859190>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars.groupby(['ma'])['s'].describe().rename(index=lbl_vals['market']).style.format('{:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Using canned software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from linearmodels.iv import IV2SLS\n",
    "from statsmodels.api import OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars['delta'] = cars['s'] / cars['s0']\n",
    "cars['delta'] = np.log(cars['delta'].values.astype(float)) ## Den stoppede med at ville g√∏re det i et skridt uden at definere type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars[\"brand\"].replace('alfa romeo', 'alfa_romeo', inplace=True)\n",
    "cars[\"brand\"] = cars[\"brand\"].str.replace('/', '', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average price of all other cars in a given year in a given market:\n",
    "# Step 1: Calculate the sum and count of prices for each year and market\n",
    "cars['sum_eurpr_ye_ma'] = cars.groupby(['ye', 'ma'])['eurpr'].transform('sum')\n",
    "cars['count_ye_ma'] = cars.groupby(['ye', 'ma'])['eurpr'].transform('count')\n",
    "\n",
    "# Step 2: Calculate the average price excluding the current observation\n",
    "cars['avg_eurpr_excl'] = (cars['sum_eurpr_ye_ma'] - cars['eurpr']) / (cars['count_ye_ma'] - 1)\n",
    "\n",
    "# Drop the intermediate columns if they are no longer needed\n",
    "cars.drop(columns=['sum_eurpr_ye_ma', 'count_ye_ma'], inplace=True)\n",
    "\n",
    "\n",
    "cars['avg_eurpr_excl'] = np.log(cars['avg_eurpr_excl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the dataframe for later making the IV-analysis\n",
    "cars_iv = cars.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_var = 'brand' # name of categorical variable\n",
    "dummies = pd.get_dummies(cars[categorical_var]) # creates a matrix of dummies for each value of dummyvar\n",
    "x_vars_dummies = list(dummies.columns[1:].values) # omit a reference category, here it is the first (hence columns[1:])\n",
    "\n",
    "# add dummies to the dataframe \n",
    "assert dummies.columns[0] not in cars.columns, f'It looks like you have already added this dummy to the dataframe. Avoid duplicates! '\n",
    "cars = pd.concat([cars,dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The left out dummy for brands is: BMW\n",
      "There are: 33 brand-dummies\n"
     ]
    }
   ],
   "source": [
    "print(f'The left out dummy for brands is: {dummies.columns[0]}')\n",
    "print(f'There are: {len(dummies.columns)} brand-dummies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['logp', 'home', 'cy', 'hp', 'we', 'li', 'sp', 'MCC', 'VW', 'alfa_romeo', 'audi', 'citroen', 'daewoo', 'daf', 'fiat', 'ford', 'honda', 'hyundai', 'innocenti', 'lancia', 'mazda', 'mercedes', 'mitsubishi', 'nissan', 'opel', 'peugeot', 'renault', 'rover', 'saab', 'seat', 'skoda', 'suzuki', 'talbot', 'talhillman', 'talmatra', 'talsimca', 'talsunb', 'toyota', 'volvo']\n"
     ]
    }
   ],
   "source": [
    "# choose your preferred variables \n",
    "#x_vars = ['logp', 'avg_eurpr_excl', 'home', 'cy', 'hp', 'we', 'li', 'sp'] + x_vars_dummies # <--- !!! CHOOSE HERE \n",
    "x_vars = ['logp', 'home', 'cy', 'hp', 'we', 'li', 'sp'] + x_vars_dummies\n",
    "print(x_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta ~ 1 + logp + home + cy + hp + we + li + sp + MCC + VW + alfa_romeo + audi + citroen + daewoo + daf + fiat + ford + honda + hyundai + innocenti + lancia + mazda + mercedes + mitsubishi + nissan + opel + peugeot + renault + rover + saab + seat + skoda + suzuki + talbot + talhillman + talmatra + talsimca + talsunb + toyota + volvo\n"
     ]
    }
   ],
   "source": [
    "# set up the estimation equation\n",
    "formula = 'delta ~ 1'\n",
    "for x_ in x_vars:\n",
    "    formula += ' + ' + x_\n",
    "print(formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>delta</td>      <th>  R-squared:         </th> <td>   0.400</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.396</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   102.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 21 Oct 2024</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:31:01</td>     <th>  Log-Likelihood:    </th> <td> -6355.6</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  5998</td>      <th>  AIC:               </th> <td>1.279e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  5958</td>      <th>  BIC:               </th> <td>1.306e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    39</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>   -8.8408</td> <td>    0.236</td> <td>  -37.483</td> <td> 0.000</td> <td>   -9.303</td> <td>   -8.378</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>logp</th>       <td>    0.0479</td> <td>    0.032</td> <td>    1.499</td> <td> 0.134</td> <td>   -0.015</td> <td>    0.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>home</th>       <td>    1.0292</td> <td>    0.022</td> <td>   47.423</td> <td> 0.000</td> <td>    0.987</td> <td>    1.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cy</th>         <td>   -0.0003</td> <td> 6.76e-05</td> <td>   -4.095</td> <td> 0.000</td> <td>   -0.000</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hp</th>         <td>   -0.0317</td> <td>    0.002</td> <td>  -16.151</td> <td> 0.000</td> <td>   -0.036</td> <td>   -0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>we</th>         <td>    0.0005</td> <td>    0.000</td> <td>    3.834</td> <td> 0.000</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>li</th>         <td>   -0.0264</td> <td>    0.011</td> <td>   -2.413</td> <td> 0.016</td> <td>   -0.048</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sp</th>         <td>    0.0187</td> <td>    0.002</td> <td>   12.404</td> <td> 0.000</td> <td>    0.016</td> <td>    0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MCC</th>        <td>   -1.0797</td> <td>    0.499</td> <td>   -2.166</td> <td> 0.030</td> <td>   -2.057</td> <td>   -0.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VW</th>         <td>    0.0961</td> <td>    0.061</td> <td>    1.582</td> <td> 0.114</td> <td>   -0.023</td> <td>    0.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>alfa_romeo</th> <td>   -0.5093</td> <td>    0.077</td> <td>   -6.598</td> <td> 0.000</td> <td>   -0.661</td> <td>   -0.358</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>audi</th>       <td>   -0.1521</td> <td>    0.066</td> <td>   -2.296</td> <td> 0.022</td> <td>   -0.282</td> <td>   -0.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>citroen</th>    <td>   -0.3539</td> <td>    0.059</td> <td>   -5.950</td> <td> 0.000</td> <td>   -0.470</td> <td>   -0.237</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>daewoo</th>     <td>   -0.5044</td> <td>    0.290</td> <td>   -1.738</td> <td> 0.082</td> <td>   -1.073</td> <td>    0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>daf</th>        <td>   -0.7233</td> <td>    0.147</td> <td>   -4.931</td> <td> 0.000</td> <td>   -1.011</td> <td>   -0.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fiat</th>       <td>   -0.1852</td> <td>    0.058</td> <td>   -3.200</td> <td> 0.001</td> <td>   -0.299</td> <td>   -0.072</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ford</th>       <td>    0.1758</td> <td>    0.058</td> <td>    3.024</td> <td> 0.003</td> <td>    0.062</td> <td>    0.290</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>honda</th>      <td>   -0.2551</td> <td>    0.086</td> <td>   -2.949</td> <td> 0.003</td> <td>   -0.425</td> <td>   -0.086</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hyundai</th>    <td>   -0.7687</td> <td>    0.253</td> <td>   -3.044</td> <td> 0.002</td> <td>   -1.264</td> <td>   -0.274</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>innocenti</th>  <td>   -1.1701</td> <td>    0.189</td> <td>   -6.185</td> <td> 0.000</td> <td>   -1.541</td> <td>   -0.799</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lancia</th>     <td>   -0.8124</td> <td>    0.080</td> <td>  -10.197</td> <td> 0.000</td> <td>   -0.969</td> <td>   -0.656</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mazda</th>      <td>   -0.1721</td> <td>    0.080</td> <td>   -2.147</td> <td> 0.032</td> <td>   -0.329</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mercedes</th>   <td>    0.3815</td> <td>    0.067</td> <td>    5.682</td> <td> 0.000</td> <td>    0.250</td> <td>    0.513</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mitsubishi</th> <td>   -0.2566</td> <td>    0.112</td> <td>   -2.287</td> <td> 0.022</td> <td>   -0.476</td> <td>   -0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nissan</th>     <td>   -0.1699</td> <td>    0.065</td> <td>   -2.597</td> <td> 0.009</td> <td>   -0.298</td> <td>   -0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>opel</th>       <td>    0.0323</td> <td>    0.059</td> <td>    0.552</td> <td> 0.581</td> <td>   -0.083</td> <td>    0.147</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>peugeot</th>    <td>   -0.0966</td> <td>    0.059</td> <td>   -1.634</td> <td> 0.102</td> <td>   -0.213</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>renault</th>    <td>    0.0066</td> <td>    0.057</td> <td>    0.115</td> <td> 0.909</td> <td>   -0.106</td> <td>    0.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rover</th>      <td>   -0.4077</td> <td>    0.065</td> <td>   -6.306</td> <td> 0.000</td> <td>   -0.534</td> <td>   -0.281</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>saab</th>       <td>   -0.8801</td> <td>    0.270</td> <td>   -3.262</td> <td> 0.001</td> <td>   -1.409</td> <td>   -0.351</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>seat</th>       <td>   -0.6178</td> <td>    0.091</td> <td>   -6.813</td> <td> 0.000</td> <td>   -0.796</td> <td>   -0.440</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>skoda</th>      <td>   -0.7885</td> <td>    0.159</td> <td>   -4.974</td> <td> 0.000</td> <td>   -1.099</td> <td>   -0.478</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>suzuki</th>     <td>   -0.7537</td> <td>    0.270</td> <td>   -2.792</td> <td> 0.005</td> <td>   -1.283</td> <td>   -0.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>talbot</th>     <td>   -0.3994</td> <td>    0.081</td> <td>   -4.951</td> <td> 0.000</td> <td>   -0.557</td> <td>   -0.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>talhillman</th> <td>   -1.0643</td> <td>    0.229</td> <td>   -4.650</td> <td> 0.000</td> <td>   -1.513</td> <td>   -0.616</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>talmatra</th>   <td>   -2.6303</td> <td>    0.500</td> <td>   -5.258</td> <td> 0.000</td> <td>   -3.611</td> <td>   -1.650</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>talsimca</th>   <td>   -0.3039</td> <td>    0.100</td> <td>   -3.035</td> <td> 0.002</td> <td>   -0.500</td> <td>   -0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>talsunb</th>    <td>   -4.1721</td> <td>    0.703</td> <td>   -5.932</td> <td> 0.000</td> <td>   -5.551</td> <td>   -2.793</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>toyota</th>     <td>    0.0513</td> <td>    0.072</td> <td>    0.714</td> <td> 0.476</td> <td>   -0.090</td> <td>    0.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>volvo</th>      <td>    0.1098</td> <td>    0.080</td> <td>    1.380</td> <td> 0.168</td> <td>   -0.046</td> <td>    0.266</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>135.717</td> <th>  Durbin-Watson:     </th> <td>   1.431</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 154.365</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.330</td>  <th>  Prob(JB):          </th> <td>3.02e-34</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.425</td>  <th>  Cond. No.          </th> <td>1.32e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.32e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  delta   R-squared:                       0.400\n",
       "Model:                            OLS   Adj. R-squared:                  0.396\n",
       "Method:                 Least Squares   F-statistic:                     102.0\n",
       "Date:                Mon, 21 Oct 2024   Prob (F-statistic):               0.00\n",
       "Time:                        20:31:01   Log-Likelihood:                -6355.6\n",
       "No. Observations:                5998   AIC:                         1.279e+04\n",
       "Df Residuals:                    5958   BIC:                         1.306e+04\n",
       "Df Model:                          39                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -8.8408      0.236    -37.483      0.000      -9.303      -8.378\n",
       "logp           0.0479      0.032      1.499      0.134      -0.015       0.110\n",
       "home           1.0292      0.022     47.423      0.000       0.987       1.072\n",
       "cy            -0.0003   6.76e-05     -4.095      0.000      -0.000      -0.000\n",
       "hp            -0.0317      0.002    -16.151      0.000      -0.036      -0.028\n",
       "we             0.0005      0.000      3.834      0.000       0.000       0.001\n",
       "li            -0.0264      0.011     -2.413      0.016      -0.048      -0.005\n",
       "sp             0.0187      0.002     12.404      0.000       0.016       0.022\n",
       "MCC           -1.0797      0.499     -2.166      0.030      -2.057      -0.102\n",
       "VW             0.0961      0.061      1.582      0.114      -0.023       0.215\n",
       "alfa_romeo    -0.5093      0.077     -6.598      0.000      -0.661      -0.358\n",
       "audi          -0.1521      0.066     -2.296      0.022      -0.282      -0.022\n",
       "citroen       -0.3539      0.059     -5.950      0.000      -0.470      -0.237\n",
       "daewoo        -0.5044      0.290     -1.738      0.082      -1.073       0.064\n",
       "daf           -0.7233      0.147     -4.931      0.000      -1.011      -0.436\n",
       "fiat          -0.1852      0.058     -3.200      0.001      -0.299      -0.072\n",
       "ford           0.1758      0.058      3.024      0.003       0.062       0.290\n",
       "honda         -0.2551      0.086     -2.949      0.003      -0.425      -0.086\n",
       "hyundai       -0.7687      0.253     -3.044      0.002      -1.264      -0.274\n",
       "innocenti     -1.1701      0.189     -6.185      0.000      -1.541      -0.799\n",
       "lancia        -0.8124      0.080    -10.197      0.000      -0.969      -0.656\n",
       "mazda         -0.1721      0.080     -2.147      0.032      -0.329      -0.015\n",
       "mercedes       0.3815      0.067      5.682      0.000       0.250       0.513\n",
       "mitsubishi    -0.2566      0.112     -2.287      0.022      -0.476      -0.037\n",
       "nissan        -0.1699      0.065     -2.597      0.009      -0.298      -0.042\n",
       "opel           0.0323      0.059      0.552      0.581      -0.083       0.147\n",
       "peugeot       -0.0966      0.059     -1.634      0.102      -0.213       0.019\n",
       "renault        0.0066      0.057      0.115      0.909      -0.106       0.119\n",
       "rover         -0.4077      0.065     -6.306      0.000      -0.534      -0.281\n",
       "saab          -0.8801      0.270     -3.262      0.001      -1.409      -0.351\n",
       "seat          -0.6178      0.091     -6.813      0.000      -0.796      -0.440\n",
       "skoda         -0.7885      0.159     -4.974      0.000      -1.099      -0.478\n",
       "suzuki        -0.7537      0.270     -2.792      0.005      -1.283      -0.225\n",
       "talbot        -0.3994      0.081     -4.951      0.000      -0.557      -0.241\n",
       "talhillman    -1.0643      0.229     -4.650      0.000      -1.513      -0.616\n",
       "talmatra      -2.6303      0.500     -5.258      0.000      -3.611      -1.650\n",
       "talsimca      -0.3039      0.100     -3.035      0.002      -0.500      -0.108\n",
       "talsunb       -4.1721      0.703     -5.932      0.000      -5.551      -2.793\n",
       "toyota         0.0513      0.072      0.714      0.476      -0.090       0.192\n",
       "volvo          0.1098      0.080      1.380      0.168      -0.046       0.266\n",
       "==============================================================================\n",
       "Omnibus:                      135.717   Durbin-Watson:                   1.431\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              154.365\n",
       "Skew:                          -0.330   Prob(JB):                     3.02e-34\n",
       "Kurtosis:                       3.425   Cond. No.                     1.32e+05\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.32e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimate the model by OLS\n",
    "OLSmodel = OLS.from_formula(formula, cars).fit()\n",
    "OLSmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'statsmodels.stats.contrast.ContrastResults'>\n",
       "<F test: F=196.4995562504705, p=0.0, df_denom=5.96e+03, df_num=39>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_formula = 'Intercept = 0, home = 0, cy = 0, hp = 0, we = 0, li = 0, sp = 0, MCC = 0, VW = 0, alfa_romeo = 0, audi = 0, citroen = 0, daewoo = 0, daf = 0, fiat = 0, ford = 0, honda = 0, hyundai = 0, innocenti = 0, lancia = 0, mazda = 0, mercedes = 0, mitsubishi = 0, nissan = 0, opel = 0, peugeot = 0, renault = 0, rover = 0, saab = 0, seat = 0, skoda = 0, suzuki = 0, talbot = 0, talhillman = 0, talmatra = 0, talsimca = 0, talsunb = 0, toyota = 0, volvo = 0'\n",
    "OLSmodel.f_test(test_formula)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate elasticities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Logit elasticities are \n",
    "\n",
    "$$\n",
    "\\mathcal{E}_{jk} \\equiv \\frac{\\partial s_{jt}}{\\partial p_{kt}} \\frac{p_{kt}}{s_{jt}} = \n",
    "\\begin{cases}\n",
    "\\alpha (\\mathbf{1}\\{j = k\\} - s_{jt}) p_{kt} & \\text{if price is in level},   \\\\\n",
    "\\alpha (\\mathbf{1}\\{j = k\\} - s_{jt})        & \\text{if price is in log }. \n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price in logs:  Avg. own-price elasticity:  4.78%\n",
      "Price in logs:  Avg. cross-price elasticity: -0.01%\n"
     ]
    }
   ],
   "source": [
    "betaOLS = OLSmodel.params\n",
    "elast_own = betaOLS['logp'] * (1 - cars['s'])\n",
    "print(f'Price in logs:  Avg. own-price elasticity: {elast_own.mean(): .2%}')\n",
    "\n",
    "elast_cross = - betaOLS['logp'] * cars['s']\n",
    "print(f'Price in logs:  Avg. cross-price elasticity: {elast_cross.mean(): .2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial s_{jt}}{\\partial p_{kt}} = \n",
    "\\begin{cases}\n",
    "\\alpha (\\mathbf{1}\\{j = k\\} - s_{jt}) s_{jt} & \\text{if price is in level},   \\\\\n",
    "\\alpha (\\mathbf{1}\\{j = k\\} - s_{jt}) \\frac{s_{jt}} {p_{kt}}      & \\text{if price is in log }. \n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars['idx'] = cars.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the marginal cost for each car-type given firms are profitmaximizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MarginalCost(dat, index, beta, pvar, price, share, firm, log=True):\n",
    "    p = dat[price].values\n",
    "    firms = dat[firm].values\n",
    "    H = (firms[:, None] == firms[None, :]).astype(np.int8)\n",
    "    s = dat[share].values       # Column 's'\n",
    "    alpha = beta[pvar]              # The given alpha value.\n",
    "\n",
    "    # Compute the size of the matrix\n",
    "    n = len(dat)\n",
    "\n",
    "    # Create an identity matrix for the I(j = k) term\n",
    "    #id_mat = np.eye(n)\n",
    "\n",
    "    #divisor = 1\n",
    "    #if log:\n",
    "    #    divisor = p[:, None]\n",
    "\n",
    "    # Compute s_dif matrix\n",
    "    #s_dif = (alpha / divisor) * s[:, None] * (id_mat - s)\n",
    "\n",
    "    s_dif = alpha * (np.diag(s) - np.outer(s, s))\n",
    "\n",
    "    # Ensure H and s_dif are numeric arrays\n",
    "    H = np.asarray(H, dtype=np.float64)\n",
    "    s_dif = np.asarray(s_dif, dtype=np.float64)\n",
    "\n",
    "    # Multiply H and s_dif element-wise\n",
    "    Hs_dif = np.multiply(H, s_dif)\n",
    "\n",
    "    # Ensure s_values is reshaped correctly and is a numeric array\n",
    "    s = s.reshape((n, 1)).astype(np.float64)\n",
    "\n",
    "    # Ensure p_values is also a numeric array\n",
    "    p = np.asarray(p, dtype=np.float64)\n",
    "    p = p.reshape((n, 1)).astype(np.float64)\n",
    "\n",
    "    # Solve the system of equations hs_dif * c = s_values\n",
    "    mc = p + np.linalg.inv(Hs_dif) @ s\n",
    "    idx = dat[index].values\n",
    "    idx = idx.reshape((n, 1)).astype(np.float64)\n",
    "    return np.hstack((idx, mc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MC_loop(dat, index, beta, pvar, price, share, firm, market, year, log=True):\n",
    "\n",
    "    mc_list = []\n",
    "\n",
    "    for ye in dat[year].unique():\n",
    "        for ma in dat[market].unique():\n",
    "            sub_dat = dat[(dat[market] == ma) & (dat[year] == ye)].copy()\n",
    "            mc = MarginalCost(sub_dat, index, beta, pvar, price, share, firm, log)\n",
    "            mc_list.append(mc)\n",
    "\n",
    "    # Vertically stack all arrays in the list into a single 2D array\n",
    "    stacked_mc = np.vstack(mc_list)\n",
    "    return stacked_mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_array = MC_loop(cars, 'idx', betaOLS, 'logp', 'eurpr', 's', 'frm', 'ma', 'ye', log=True)  # mc_array[:, 0] is idx values, mc_array[:, 1] is mc values\n",
    "mc_dict = dict(mc_array)\n",
    "cars['mc_vanilla'] = cars['idx'].map(mc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ccp(dat, beta, xvars, p, pvar, log): \n",
    "    '''\n",
    "    INPUTS: \n",
    "        p: (J,) vector of prices\n",
    "        t: (int) market index\n",
    "    OUTPUTS:\n",
    "        ccp: (J+1,) vector of conditional choice probabilities (0 = outside option)\n",
    "    '''\n",
    "    J = len(dat)\n",
    "    assert p.shape == (J,)\n",
    "\n",
    "    delta = np.zeros((J,))\n",
    "    if 'Intercept' in beta:\n",
    "        delta = np.ones((J,)) * beta['Intercept']\n",
    "\n",
    "    for var in xvars:\n",
    "        if var == pvar:\n",
    "            continue\n",
    "        delta += dat[var].values * beta[var]\n",
    "\n",
    "    if log:\n",
    "        delta += np.log(p) * beta[pvar]\n",
    "    else:\n",
    "        delta += p * beta[pvar]\n",
    "    \n",
    "    # 2. insert a zero in the first position for the outside option\n",
    "    delta = np.insert(delta, 0, 0.0)\n",
    "    \n",
    "    # 3. max-rescale (to avoid numerical issues)\n",
    "    delta -= delta.max() # no need for keepdims=True since delta.max() is a scalar\n",
    "\n",
    "    # 4. compute the CCP\n",
    "    ed = np.exp(delta)\n",
    "    ccp = ed / ed.sum()\n",
    "\n",
    "    return ccp # (J+1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeta(p, mc, H, dat, beta, xvars, pvar, log):\n",
    "    J = len(p)\n",
    "    assert (p.shape == (J,)) and (mc.shape == (J,)) and (H.shape == (J, J))\n",
    "    s = ccp(dat, beta, xvars, p, pvar, log)\n",
    "    s = s[1:] # remove outside option\n",
    "    \n",
    "    Lambda = beta[pvar] * np.diag(s)\n",
    "    HLambda = np.multiply(H, Lambda)\n",
    "    invHLambda = np.linalg.inv(HLambda)\n",
    "    Gamma = beta[pvar] * np.outer(s, s)\n",
    "    HGamma = np.multiply(H, Gamma)\n",
    "    z = invHLambda @ (HGamma @ (p - mc) -  s)\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_nash_MS(p_start, mc, H, dat, xvars, pvar, beta, log=True, maxit=1000, tol=1e-6, DOPRINT=False): \n",
    "    p_prev = p_start.copy()\n",
    "    for it in range(maxit): \n",
    "        p_next = mc + zeta(p_prev, mc, H, dat, beta, xvars, pvar, log)\n",
    "        if np.linalg.norm(p_next - p_prev) < tol: \n",
    "            if DOPRINT: \n",
    "                print(f'Converged after {it} iterations')\n",
    "            break \n",
    "        p_prev = p_next\n",
    "    return p_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_in_ye(dat, market, firm, mc_var, xvars, pvar, beta):\n",
    "    p_list = []\n",
    "    for ma in dat[market].unique():\n",
    "        sub_dat = dat[(dat[market] == ma)].copy()\n",
    "        firms = sub_dat[firm].values\n",
    "        H = (firms[:, None] == firms[None, :]).astype(np.int8)\n",
    "        mc = sub_dat[mc_var].values\n",
    "        p_start = mc*1.5\n",
    "        p = solve_nash_MS(p_start, mc, H, sub_dat, xvars, pvar, beta)\n",
    "        p_list += [[p]]\n",
    "\n",
    "    return p_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars['frm_m'] = cars['frm']\n",
    "cars.loc[cars['frm_m'] == 4, 'frm_m'] = 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat99 = cars[(cars['ye'] == 99)].copy()\n",
    "p_merger = p_in_ye(dat99, 'ma', 'frm_m', 'mc_vanilla', x_vars, 'logp', betaOLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([13664.1216386 , 24955.96734172, 12886.12315699,  5958.94384022,\n",
      "        6072.94444648,  8103.5792121 , 10703.55089179,  8331.29361169,\n",
      "       19554.94332661, 25585.37887349,  6756.22597238, 13967.82509347,\n",
      "        9678.82118722,  6243.8599734 ,  9451.12413355,  7021.89655878,\n",
      "        6319.71442987,  6528.51203825,  8727.95151125,  7422.37092497,\n",
      "       10172.26789763, 14461.27180388, 22375.05403044, 17080.22004606,\n",
      "       10437.08862403, 13189.71150018, 12430.65343043,  7572.18201942,\n",
      "        9678.80134393,  5881.38243433, 13267.2745246 , 13379.30028553,\n",
      "        8710.98643824,  6357.61290351, 11764.48043599, 10039.32432929,\n",
      "        7135.8209109 , 12705.71811281,  7192.63949953, 11576.63215544])]\n"
     ]
    }
   ],
   "source": [
    "print(p_merger[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV-estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the Hausman-instrument. Start by computing this for the M-1 markets for each car."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the the country-column is treated as a string in the dataframe\n",
    "cars_iv['ma'] = cars_iv['ma'].astype(str)\n",
    "\n",
    "# Get the unique list of countries as strings\n",
    "countries = cars_iv['ma'].unique()\n",
    "\n",
    "# Step 2: Create the four additional columns for prices from the other four countries\n",
    "for country in countries:\n",
    "    # Create a new column for each country\n",
    "    column_name = f'eurpr_in_{country}'\n",
    "    \n",
    "    # Create a copy of the dataframe that only includes the rows for the given country\n",
    "    country_data = cars_iv[cars_iv['ma'] == country][['ye', 'type', 'eurpr']]\n",
    "    \n",
    "    # Rename the 'eurpr' column in this temporary dataframe to avoid confusion\n",
    "    country_data = country_data.rename(columns={'eurpr': column_name})\n",
    "    \n",
    "    # Merge the country-specific prices back into the main dataframe on 'ye' and 'type'\n",
    "    cars_iv = cars_iv.merge(country_data, on=['ye', 'type'], how='left')\n",
    "\n",
    "# Step 4: For each row, remove the price of the current country from the new columns\n",
    "for country in countries:\n",
    "    column_name = f'eurpr_in_{country}'\n",
    "    \n",
    "    # Set the column to NaN where the country matches the current row\n",
    "    cars_iv.loc[cars['ma'] == country, column_name] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_columns = [f'eurpr_in_{country}' for country in countries]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the Hausman-instrument we apply\n",
    "cars_iv['avg_eurpr_other'] = cars_iv[price_columns].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_iv = cars_iv[cars_iv['avg_eurpr_other'].notna()] # drop NA observations for the instrument. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define new dummies (this is why we made a new dataframe for the IV-estimation)\n",
    "categorical_var = 'brand' # name of categorical variable\n",
    "dummies = pd.get_dummies(cars_iv[categorical_var]) # creates a matrix of dummies for each value of dummyvar\n",
    "iv_dummies = list(dummies.columns[1:].values) # omit a reference category, here it is the first (hence columns[1:])\n",
    "\n",
    "# add dummies to the dataframe \n",
    "assert dummies.columns[0] not in cars_iv.columns, f'It looks like you have already added this dummy to the dataframe. Avoid duplicates! '\n",
    "cars_iv = pd.concat([cars_iv,dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the exogenous variables in our model \n",
    "#x_vars_exog = ['avg_eurpr_excl', 'home', 'cy', 'hp', 'we', 'li', 'sp'] + iv_dummies\n",
    "\n",
    "x_vars_exog = ['home', 'cy', 'hp', 'we', 'li', 'sp'] + iv_dummies\n",
    "\n",
    "# Define the endogenous variables and their corresponding instruments\n",
    "x_vars_endog = ['[logp ~ avdexr]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta ~ 1 + home + cy + hp + we + li + sp + MCC + VW + alfa_romeo + audi + citroen + daewoo + daf + fiat + ford + honda + hyundai + innocenti + lancia + mazda + mercedes + mitsubishi + nissan + opel + peugeot + renault + rover + saab + seat + skoda + suzuki + talbot + talhillman + talmatra + talsimca + talsunb + toyota + volvo + [logp ~ avdexr]\n"
     ]
    }
   ],
   "source": [
    "# set up the estimation equation\n",
    "iv_formula = 'delta ~ 1'\n",
    "for x_ in x_vars_exog:\n",
    "    iv_formula += ' + ' + x_\n",
    "for x_ in x_vars_endog:\n",
    "    iv_formula += ' + ' + x_\n",
    "\n",
    "\n",
    "print(iv_formula)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PSand\\anaconda3\\lib\\site-packages\\linearmodels\\iv\\model.py:557: MissingValueWarning: \n",
      "Inputs contain missing values. Dropping rows with missing observations.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>IV-2SLS Estimation Summary</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>delta</td>      <th>  R-squared:         </th>  <td>0.3006</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Estimator:</th>             <td>IV-2SLS</td>     <th>  Adj. R-squared:    </th>  <td>0.2960</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>       <td>5998</td>       <th>  F-statistic:       </th> <td>1.359e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, Oct 21 2024</td> <th>  P-value (F-stat)   </th>  <td>0.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>20:31:02</td>     <th>  Distribution:      </th> <td>chi2(39)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Cov. Estimator:</th>        <td>robust</td>      <th>                     </th>     <td></td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td></td>         <th>                     </th>     <td></td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<caption>Parameter Estimates</caption>\n",
       "<tr>\n",
       "       <td></td>      <th>Parameter</th> <th>Std. Err.</th> <th>T-stat</th>  <th>P-value</th> <th>Lower CI</th> <th>Upper CI</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>   <td>-3.4559</td>   <td>1.7002</td>   <td>-2.0327</td> <td>0.0421</td>   <td>-6.7882</td>  <td>-0.1236</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>home</th>        <td>1.0914</td>    <td>0.0304</td>   <td>35.935</td>  <td>0.0000</td>   <td>1.0319</td>   <td>1.1509</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cy</th>          <td>-0.0005</td>   <td>0.0001</td>   <td>-4.6584</td> <td>0.0000</td>   <td>-0.0007</td>  <td>-0.0003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hp</th>          <td>-0.0378</td>   <td>0.0032</td>   <td>-11.854</td> <td>0.0000</td>   <td>-0.0441</td>  <td>-0.0316</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>we</th>          <td>0.0018</td>    <td>0.0004</td>   <td>4.1698</td>  <td>0.0000</td>   <td>0.0009</td>   <td>0.0026</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>li</th>          <td>-0.1865</td>   <td>0.0514</td>   <td>-3.6311</td> <td>0.0003</td>   <td>-0.2871</td>  <td>-0.0858</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sp</th>          <td>0.0453</td>    <td>0.0086</td>   <td>5.2783</td>  <td>0.0000</td>   <td>0.0285</td>   <td>0.0621</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MCC</th>         <td>-0.8340</td>   <td>0.1813</td>   <td>-4.5994</td> <td>0.0000</td>   <td>-1.1894</td>  <td>-0.4786</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VW</th>          <td>0.1743</td>    <td>0.0671</td>   <td>2.5972</td>  <td>0.0094</td>   <td>0.0428</td>   <td>0.3058</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>alfa_romeo</th>  <td>-0.7007</td>   <td>0.0959</td>   <td>-7.3038</td> <td>0.0000</td>   <td>-0.8888</td>  <td>-0.5127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>audi</th>        <td>-0.1889</td>   <td>0.0680</td>   <td>-2.7765</td> <td>0.0055</td>   <td>-0.3222</td>  <td>-0.0555</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>citroen</th>     <td>-0.5172</td>   <td>0.0776</td>   <td>-6.6612</td> <td>0.0000</td>   <td>-0.6694</td>  <td>-0.3650</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>daewoo</th>      <td>-0.3749</td>   <td>0.1761</td>   <td>-2.1284</td> <td>0.0333</td>   <td>-0.7201</td>  <td>-0.0297</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>daf</th>         <td>-1.1673</td>   <td>0.2147</td>   <td>-5.4366</td> <td>0.0000</td>   <td>-1.5881</td>  <td>-0.7465</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fiat</th>        <td>-0.3477</td>   <td>0.0805</td>   <td>-4.3199</td> <td>0.0000</td>   <td>-0.5054</td>  <td>-0.1899</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ford</th>        <td>0.1650</td>    <td>0.0567</td>   <td>2.9093</td>  <td>0.0036</td>   <td>0.0539</td>   <td>0.2762</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>honda</th>       <td>-0.3130</td>   <td>0.0940</td>   <td>-3.3310</td> <td>0.0009</td>   <td>-0.4972</td>  <td>-0.1288</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hyundai</th>     <td>-0.9475</td>   <td>0.2084</td>   <td>-4.5476</td> <td>0.0000</td>   <td>-1.3559</td>  <td>-0.5391</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>innocenti</th>   <td>-1.4927</td>   <td>0.1938</td>   <td>-7.7011</td> <td>0.0000</td>   <td>-1.8725</td>  <td>-1.1128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>lancia</th>      <td>-1.0288</td>   <td>0.1116</td>   <td>-9.2150</td> <td>0.0000</td>   <td>-1.2476</td>  <td>-0.8100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mazda</th>       <td>-0.1989</td>   <td>0.0687</td>   <td>-2.8952</td> <td>0.0038</td>   <td>-0.3335</td>  <td>-0.0642</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mercedes</th>    <td>0.6807</td>    <td>0.1123</td>   <td>6.0638</td>  <td>0.0000</td>   <td>0.4607</td>   <td>0.9007</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>mitsubishi</th>  <td>-0.2226</td>   <td>0.0927</td>   <td>-2.4010</td> <td>0.0164</td>   <td>-0.4043</td>  <td>-0.0409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nissan</th>      <td>-0.2135</td>   <td>0.0625</td>   <td>-3.4149</td> <td>0.0006</td>   <td>-0.3361</td>  <td>-0.0910</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>opel</th>        <td>-0.0562</td>   <td>0.0663</td>   <td>-0.8475</td> <td>0.3967</td>   <td>-0.1860</td>  <td>0.0737</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>peugeot</th>     <td>-0.1939</td>   <td>0.0698</td>   <td>-2.7771</td> <td>0.0055</td>   <td>-0.3308</td>  <td>-0.0571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>renault</th>     <td>-0.0752</td>   <td>0.0626</td>   <td>-1.2000</td> <td>0.2301</td>   <td>-0.1979</td>  <td>0.0476</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rover</th>       <td>-0.4187</td>   <td>0.0634</td>   <td>-6.5987</td> <td>0.0000</td>   <td>-0.5430</td>  <td>-0.2943</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>saab</th>        <td>-1.3385</td>   <td>0.2168</td>   <td>-6.1744</td> <td>0.0000</td>   <td>-1.7634</td>  <td>-0.9136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>seat</th>        <td>-0.5439</td>   <td>0.0766</td>   <td>-7.0980</td> <td>0.0000</td>   <td>-0.6941</td>  <td>-0.3937</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>skoda</th>       <td>-0.6077</td>   <td>0.1142</td>   <td>-5.3216</td> <td>0.0000</td>   <td>-0.8315</td>  <td>-0.3838</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>suzuki</th>      <td>-0.7299</td>   <td>0.0880</td>   <td>-8.2941</td> <td>0.0000</td>   <td>-0.9024</td>  <td>-0.5574</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>talbot</th>      <td>-0.6768</td>   <td>0.1200</td>   <td>-5.6416</td> <td>0.0000</td>   <td>-0.9119</td>  <td>-0.4417</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>talhillman</th>  <td>-1.6362</td>   <td>0.3439</td>   <td>-4.7577</td> <td>0.0000</td>   <td>-2.3102</td>  <td>-0.9621</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>talmatra</th>    <td>-3.1896</td>   <td>0.1932</td>   <td>-16.506</td> <td>0.0000</td>   <td>-3.5683</td>  <td>-2.8109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>talsimca</th>    <td>-0.8555</td>   <td>0.2099</td>   <td>-4.0754</td> <td>0.0000</td>   <td>-1.2670</td>  <td>-0.4441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>talsunb</th>     <td>-5.1290</td>   <td>0.3063</td>   <td>-16.744</td> <td>0.0000</td>   <td>-5.7294</td>  <td>-4.5286</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>toyota</th>      <td>-0.0639</td>   <td>0.0790</td>   <td>-0.8092</td> <td>0.4184</td>   <td>-0.2188</td>  <td>0.0909</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>volvo</th>       <td>0.3745</td>    <td>0.1117</td>   <td>3.3531</td>  <td>0.0008</td>   <td>0.1556</td>   <td>0.5933</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>logp</th>        <td>-0.9573</td>   <td>0.3169</td>   <td>-3.0205</td> <td>0.0025</td>   <td>-1.5785</td>  <td>-0.3361</td>\n",
       "</tr>\n",
       "</table><br/><br/>Endogenous: logp<br/>Instruments: avdexr<br/>Robust Covariance (Heteroskedastic)<br/>Debiased: False"
      ],
      "text/plain": [
       "<class 'linearmodels.compat.statsmodels.Summary'>\n",
       "\"\"\"\n",
       "                          IV-2SLS Estimation Summary                          \n",
       "==============================================================================\n",
       "Dep. Variable:                  delta   R-squared:                      0.3006\n",
       "Estimator:                    IV-2SLS   Adj. R-squared:                 0.2960\n",
       "No. Observations:                5998   F-statistic:                 1.359e+05\n",
       "Date:                Mon, Oct 21 2024   P-value (F-stat)                0.0000\n",
       "Time:                        20:31:02   Distribution:                 chi2(39)\n",
       "Cov. Estimator:                robust                                         \n",
       "                                                                              \n",
       "                             Parameter Estimates                              \n",
       "==============================================================================\n",
       "            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     -3.4559     1.7002    -2.0327     0.0421     -6.7882     -0.1236\n",
       "home           1.0914     0.0304     35.935     0.0000      1.0319      1.1509\n",
       "cy            -0.0005     0.0001    -4.6584     0.0000     -0.0007     -0.0003\n",
       "hp            -0.0378     0.0032    -11.854     0.0000     -0.0441     -0.0316\n",
       "we             0.0018     0.0004     4.1698     0.0000      0.0009      0.0026\n",
       "li            -0.1865     0.0514    -3.6311     0.0003     -0.2871     -0.0858\n",
       "sp             0.0453     0.0086     5.2783     0.0000      0.0285      0.0621\n",
       "MCC           -0.8340     0.1813    -4.5994     0.0000     -1.1894     -0.4786\n",
       "VW             0.1743     0.0671     2.5972     0.0094      0.0428      0.3058\n",
       "alfa_romeo    -0.7007     0.0959    -7.3038     0.0000     -0.8888     -0.5127\n",
       "audi          -0.1889     0.0680    -2.7765     0.0055     -0.3222     -0.0555\n",
       "citroen       -0.5172     0.0776    -6.6612     0.0000     -0.6694     -0.3650\n",
       "daewoo        -0.3749     0.1761    -2.1284     0.0333     -0.7201     -0.0297\n",
       "daf           -1.1673     0.2147    -5.4366     0.0000     -1.5881     -0.7465\n",
       "fiat          -0.3477     0.0805    -4.3199     0.0000     -0.5054     -0.1899\n",
       "ford           0.1650     0.0567     2.9093     0.0036      0.0539      0.2762\n",
       "honda         -0.3130     0.0940    -3.3310     0.0009     -0.4972     -0.1288\n",
       "hyundai       -0.9475     0.2084    -4.5476     0.0000     -1.3559     -0.5391\n",
       "innocenti     -1.4927     0.1938    -7.7011     0.0000     -1.8725     -1.1128\n",
       "lancia        -1.0288     0.1116    -9.2150     0.0000     -1.2476     -0.8100\n",
       "mazda         -0.1989     0.0687    -2.8952     0.0038     -0.3335     -0.0642\n",
       "mercedes       0.6807     0.1123     6.0638     0.0000      0.4607      0.9007\n",
       "mitsubishi    -0.2226     0.0927    -2.4010     0.0164     -0.4043     -0.0409\n",
       "nissan        -0.2135     0.0625    -3.4149     0.0006     -0.3361     -0.0910\n",
       "opel          -0.0562     0.0663    -0.8475     0.3967     -0.1860      0.0737\n",
       "peugeot       -0.1939     0.0698    -2.7771     0.0055     -0.3308     -0.0571\n",
       "renault       -0.0752     0.0626    -1.2000     0.2301     -0.1979      0.0476\n",
       "rover         -0.4187     0.0634    -6.5987     0.0000     -0.5430     -0.2943\n",
       "saab          -1.3385     0.2168    -6.1744     0.0000     -1.7634     -0.9136\n",
       "seat          -0.5439     0.0766    -7.0980     0.0000     -0.6941     -0.3937\n",
       "skoda         -0.6077     0.1142    -5.3216     0.0000     -0.8315     -0.3838\n",
       "suzuki        -0.7299     0.0880    -8.2941     0.0000     -0.9024     -0.5574\n",
       "talbot        -0.6768     0.1200    -5.6416     0.0000     -0.9119     -0.4417\n",
       "talhillman    -1.6362     0.3439    -4.7577     0.0000     -2.3102     -0.9621\n",
       "talmatra      -3.1896     0.1932    -16.506     0.0000     -3.5683     -2.8109\n",
       "talsimca      -0.8555     0.2099    -4.0754     0.0000     -1.2670     -0.4441\n",
       "talsunb       -5.1290     0.3063    -16.744     0.0000     -5.7294     -4.5286\n",
       "toyota        -0.0639     0.0790    -0.8092     0.4184     -0.2188      0.0909\n",
       "volvo          0.3745     0.1117     3.3531     0.0008      0.1556      0.5933\n",
       "logp          -0.9573     0.3169    -3.0205     0.0025     -1.5785     -0.3361\n",
       "==============================================================================\n",
       "\n",
       "Endogenous: logp\n",
       "Instruments: avdexr\n",
       "Robust Covariance (Heteroskedastic)\n",
       "Debiased: False\n",
       "\"\"\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimate the model by OLS\n",
    "IVmodel = IV2SLS.from_formula(iv_formula, cars_iv).fit()\n",
    "IVmodel.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price in logs:  Avg. own-price elasticity: -95.61%\n",
      "Price in logs:  Avg. cross-price elasticity:  0.12%\n"
     ]
    }
   ],
   "source": [
    "beta_iv = IVmodel.params\n",
    "elast_own_iv = beta_iv['logp'] * (1 - cars['s'])\n",
    "print(f'Price in logs:  Avg. own-price elasticity: {elast_own_iv.mean(): .2%}')\n",
    "\n",
    "elast_cross_iv = - beta_iv['logp'] * cars['s']\n",
    "print(f'Price in logs:  Avg. cross-price elasticity: {elast_cross_iv.mean(): .2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_array = MC_loop(cars, 'idx', beta_iv, 'logp', 'eurpr', 's', 'frm', 'ma', 'ye', log=True)  # mc_array[:, 0] is idx values, mc_array[:, 1] is mc values\n",
    "mc_dict = dict(mc_array)\n",
    "cars['mc_iv'] = cars['idx'].map(mc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv_xvars = x_vars_exog + ['logp']\n",
    "dat99 = cars[(cars['ye'] == 99)].copy()\n",
    "p_merger_iv = p_in_ye(dat99, 'ma', 'frm_m', 'mc_iv', x_vars, 'logp', beta_iv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([13664.08209663, 24955.92779975, 12885.9832499 ,  5959.06525625,\n",
       "         6072.92589449,  8103.56066012, 10703.53233981,  8331.29497165,\n",
       "        19554.93499286, 25585.37053973,  6756.12564444, 13967.72476553,\n",
       "         9678.72085928,  6243.7200663 ,  9450.98422646,  7021.8172097 ,\n",
       "         6319.63508079,  6528.39060856,  8727.9327994 ,  7422.24949528,\n",
       "        10172.14646793, 14461.15037418, 22374.93260075, 17080.09861637,\n",
       "        10437.08176659, 13189.63215111, 12430.51352334,  7572.17971495,\n",
       "         9678.72199486,  5881.24252724, 13267.25597262, 13379.42170156,\n",
       "         8710.84653115,  6357.59435153, 11764.47210223, 10039.30577731,\n",
       "         7135.6810038 , 12705.69940096,  7192.62078768, 11576.51072575])]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_merger_iv[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
